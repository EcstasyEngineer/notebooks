{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "# name of channel to be scanned\n",
    "channel_prefix = \"https://www.youtube.com/\"\n",
    "#channel = \"@StronnyCuttles\"\n",
    "channel = \"@ShibiCottonbum\"\n",
    "#channel = \"@ImmyBisou\"\n",
    "#channel = \"@IceySnowpaws\"\n",
    "#channel = \"@MercyModiste\"\n",
    "#channel = \"@AzuraDulait\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WmFvJ9NbjVs\n",
      "C2Up8kSa4lM\n",
      "i7GN2f10VIQ\n",
      "8v3Jj4ItmzE\n",
      "iOCjBHb4t50\n",
      "GGhc8LeQqSw\n",
      "df5OIRbwWJU\n",
      "PF_dHkE1_rI\n",
      "jDT-SCtswq0\n",
      "DafZTKcNKCg\n",
      "j7bTZIMNkVw\n",
      "Wh9CmkbYLMY\n",
      "8uuXS7l1LnE\n",
      "ts68uC4-cI4\n",
      "nFWmrZnP_SI\n",
      "yE3sJZUa4XM\n",
      "KzDUmFGef3c\n",
      "Bth6F5wbaP8\n",
      "7RPhHyYIEo0\n",
      "xA0TXX3roDg\n",
      "yK8s8ZOrku0\n",
      "OEA6tIjKplA\n",
      "MvyhWT9AApM\n",
      "17St8KhMArg\n",
      "gTbusIo3cnk\n",
      "6NZZuLTc5gs\n",
      "CO562tfp7kU\n",
      "5vXJTNCGiiA\n",
      "5N86tMvqi4c\n",
      "NokRLOmFGa4\n"
     ]
    }
   ],
   "source": [
    "try:   os.mkdir(channel)\n",
    "except:   pass\n",
    "try:   os.mkdir(f\"{channel}/downloaded\")\n",
    "except:   pass\n",
    "try:   os.mkdir(f\"{channel}/processed\")\n",
    "except:   pass\n",
    "try:   os.mkdir(f\"{channel}/transcripts\")\n",
    "except:   pass\n",
    "# file containing keywords\n",
    "keywords_file = \"keywords.txt\"\n",
    "\n",
    "# file containing thematic searches\n",
    "thematic_file = \"thematic.txt\"\n",
    "\n",
    "# scan channel for videos\n",
    "# live videos\n",
    "os.system(f\"yt-dlp --get-id --skip-download {channel_prefix+channel} > {channel}/videos.txt\")\n",
    "videos = []\n",
    "with open(f\"{channel}/videos.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"Error\"):\n",
    "            continue\n",
    "        videos.append(line.strip())\n",
    "\n",
    "# look for filenames in {channel}/downloaded for already downloaded videos\n",
    "# the file name contains the video id in the following format:\n",
    "# „ÄêSupermarket Simulator„ÄëDefinitely not drunk on the job üêêüçº„ÄêVAllure„Äë [i3rrDSjokF4].webm\n",
    "# where [i3rrDSjokF4] is the video id\n",
    "downloaded = []\n",
    "for file in os.listdir(f\"{channel}/downloaded\"):\n",
    "    if file.endswith(\".webm\"):\n",
    "        m = re.search(r\"\\[(.*?)\\]\", file)\n",
    "        if m:\n",
    "            downloaded.append(m.group(1))\n",
    "            \n",
    "# do the same for transcripts\n",
    "transcripts = []\n",
    "for file in os.listdir(f\"{channel}/transcripts\"):\n",
    "    if file.endswith(\".srt\"):\n",
    "        m = re.search(r\"\\[([^\\[\\]]+)\\](?!.*\\[)\", file)\n",
    "        if m:\n",
    "            transcripts.append(m.group(1))\n",
    "\n",
    "\n",
    "# compare list of videos to videos already downloaded\n",
    "to_download = list(set(videos) - set(downloaded) - set(transcripts))\n",
    "for download in to_download:\n",
    "    print(f\"{download}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading WmFvJ9NbjVs\n",
      "Downloading C2Up8kSa4lM\n",
      "Downloading i7GN2f10VIQ\n",
      "Downloading 8v3Jj4ItmzE\n",
      "Downloading iOCjBHb4t50\n",
      "Error downloading iOCjBHb4t50\n",
      "Downloading GGhc8LeQqSw\n",
      "Downloading df5OIRbwWJU\n",
      "Downloading PF_dHkE1_rI\n",
      "Downloading jDT-SCtswq0\n",
      "Downloading DafZTKcNKCg\n",
      "Downloading j7bTZIMNkVw\n",
      "Downloading Wh9CmkbYLMY\n",
      "Downloading 8uuXS7l1LnE\n",
      "Downloading ts68uC4-cI4\n",
      "Downloading nFWmrZnP_SI\n",
      "Downloading yE3sJZUa4XM\n",
      "Downloading KzDUmFGef3c\n",
      "Downloading Bth6F5wbaP8\n",
      "Downloading 7RPhHyYIEo0\n",
      "Downloading xA0TXX3roDg\n",
      "Downloading yK8s8ZOrku0\n",
      "Downloading OEA6tIjKplA\n",
      "Downloading MvyhWT9AApM\n",
      "Downloading 17St8KhMArg\n",
      "Downloading gTbusIo3cnk\n",
      "Downloading 6NZZuLTc5gs\n",
      "Downloading CO562tfp7kU\n",
      "Downloading 5vXJTNCGiiA\n",
      "Downloading 5N86tMvqi4c\n",
      "Downloading NokRLOmFGa4\n"
     ]
    }
   ],
   "source": [
    "newly_downloaded = []\n",
    "for video in to_download:\n",
    "    print(f\"Downloading {video}\")\n",
    "    #output = os.system(f\"yt-dlp -f bestaudio -P {channel}/downloaded {channel_prefix}watch?v={video}\")\n",
    "    output = os.system(f\"yt-dlp --write-subs --sub-lang live_chat -f bestaudio -P {channel}/downloaded {channel_prefix}watch?v={video}\")\n",
    "    if output!=0:\n",
    "        print(f\"Error downloading {video}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#collect file names in {channel}/downloaded\n",
    "downloaded_files = os.listdir(f\"{channel}/downloaded\")\n",
    "for file in downloaded_files:\n",
    "    if file.endswith(\".webm\") or file.endswith(\".m4a\"):\n",
    "        #result = os.system(f\"whisper \\\"{channel}/downloaded/{file}\\\" --device cuda --output_dir --language English --model large-v3 \\\"{channel}/transcripts/\\\"\")\n",
    "        result = os.system(f\"whisper \\\"{channel}/downloaded/{file}\\\" --device cuda --language English --output_dir \\\"{channel}/transcripts/\\\"\")\n",
    "        if result==0:\n",
    "            #move file to {channel}/processed\n",
    "            try:\n",
    "                os.rename(f\"{channel}/downloaded/{file}\", f\"{channel}/processed/{file}\")\n",
    "            except:\n",
    "                print(f\"Error moving {file} to {channel}/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def create_histogram(data, window_size_seconds):\n",
    "    \"\"\"\n",
    "    Create a histogram of the chat messages based on the given window size.\n",
    "    \"\"\"\n",
    "    # Calculate start and end times\n",
    "    start_time = min(data)\n",
    "    end_time = max(data)\n",
    "    \n",
    "    # Initialize the bins for the histogram\n",
    "    bins = defaultdict(int)\n",
    "    current_window_start = start_time\n",
    "\n",
    "    while current_window_start <= end_time:\n",
    "        next_window_start = current_window_start + timedelta(seconds=window_size_seconds)\n",
    "        # Count messages in the current window\n",
    "        for timestamp in data:\n",
    "            if current_window_start <= timestamp < next_window_start:\n",
    "                bins[current_window_start] += 1\n",
    "        current_window_start = next_window_start\n",
    "\n",
    "    # Plot the histogram\n",
    "    plt.bar(bins.keys(), bins.values(), width=timedelta(seconds=window_size_seconds), align='edge')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Number of Chat Messages')\n",
    "    plt.title(f'Chat Messages Histogram (Window Size: {window_size_seconds} seconds)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# move and transform chat scripts. we want to extract user, timestamp and message\n",
    "# chat scripts are in the format:\n",
    "#{\"clickTrackingParams\": \"CAEQl98BIhMI0Mqgo6G_iAMV-JzCAR2cWziB\", \"replayChatItemAction\": {\"actions\": [{\"clickTrackingParams\": \"CAEQl98BIhMI0Mqgo6G_iAMV-JzCAR2cWziB\", \"addChatItemAction\": {\"item\": {\"liveChatTextMessageRenderer\": {\"message\": {\"runs\": [{\"emoji\": {\"emojiId\": \"ü©∑\", \"shortcuts\": [\":pink_heart:\"], \"searchTerms\": [\"pink\", \"heart\"], \"image\": {\"thumbnails\": [{\"url\": \"https://fonts.gstatic.com/s/e/notoemoji/15.1/1fa77/72.png\"}], \"accessibility\": {\"accessibilityData\": {\"label\": \"ü©∑\"}}}}}, {\"emoji\": {\"emojiId\": \"ü§ç\", \"shortcuts\": [\":white_heart:\"], \"searchTerms\": [\"white\", \"heart\"], \"image\": {\"thumbnails\": [{\"url\": \"https://fonts.gstatic.com/s/e/notoemoji/15.1/1f90d/72.png\"}], \"accessibility\": {\"accessibilityData\": {\"label\": \"ü§ç\"}}}}}, {\"emoji\": {\"emojiId\": \"ü§é\", \"shortcuts\": [\":brown_heart:\"], \"searchTerms\": [\"brown\", \"heart\"], \"image\": {\"thumbnails\": [{\"url\": \"https://fonts.gstatic.com/s/e/notoemoji/15.1/1f90e/72.png\"}], \"accessibility\": {\"accessibilityData\": {\"label\": \"ü§é\"}}}}}, {\"emoji\": {\"emojiId\": \"‚ù§\", \"shortcuts\": [\":red_heart:\", \":heart:\", \"<3\"], \"searchTerms\": [\"red\", \"heart\"], \"image\": {\"thumbnails\": [{\"url\": \"https://fonts.gstatic.com/s/e/notoemoji/15.1/2764/72.png\"}], \"accessibility\": {\"accessibilityData\": {\"label\": \"‚ù§\"}}}}}]}, \"authorName\": {\"simpleText\": \"TappedPotentialüê∞üë†\"}, \"authorPhoto\": {\"thumbnails\": [{\"url\": \"https://yt4.ggpht.com/mAj0LNN_j5Bv3kr0iTP6bNsE-BIwkoUXCqIOR1zahwcF7Q46xBzVp3JrCuBkwGhRRmO8_0YOlA=s32-c-k-c0x00ffffff-no-rj\", \"width\": 32, \"height\": 32}, {\"url\": \"https://yt4.ggpht.com/mAj0LNN_j5Bv3kr0iTP6bNsE-BIwkoUXCqIOR1zahwcF7Q46xBzVp3JrCuBkwGhRRmO8_0YOlA=s64-c-k-c0x00ffffff-no-rj\", \"width\": 64, \"height\": 64}]}, \"contextMenuEndpoint\": {\"clickTrackingParams\": \"CAEQl98BIhMI0Mqgo6G_iAMV-JzCAR2cWziB\", \"commandMetadata\": {\"webCommandMetadata\": {\"ignoreNavigation\": true}}, \"liveChatItemContextMenuEndpoint\": {\"params\": \"Q2g0S0hBb2FRMHRwV1RCMlRHWnlOR2RFUmxSclN6Rm5RV1JJVW1OSlFWRWFLU29uQ2hoVlEzWlplbmRGYTBOUk1qZG5VR0ZxTlRSM1FuTldUMmNTQzNSek5qaDFRelF0WTBrMElBRW9BVElhQ2hoVlF6bDBjVjlpYlVSbU9YYzVNblpFYm1ReWIwdzJNbWM0QWtnQlVBRSUzRA==\"}}, \"id\": \"ChwKGkNLaVkwdkxmcjRnREZUa0sxZ0FkSFJjSUFR\", \"timestampUsec\": \"1725674881850547\", \"authorBadges\": [{\"liveChatAuthorBadgeRenderer\": {\"customThumbnail\": {\"thumbnails\": [{\"url\": \"https://yt3.ggpht.com/LROENIDC2LQf2oAC1WcICEsPbihMHhp5APeKA9jks871KM4K8lrSQN_uoK85gmE3c8qmjFc96Q=s16-c-k\", \"width\": 16, \"height\": 16}, {\"url\": \"https://yt3.ggpht.com/LROENIDC2LQf2oAC1WcICEsPbihMHhp5APeKA9jks871KM4K8lrSQN_uoK85gmE3c8qmjFc96Q=s32-c-k\", \"width\": 32, \"height\": 32}]}, \"tooltip\": \"Member (2 months)\", \"accessibility\": {\"accessibilityData\": {\"label\": \"Member (2 months)\"}}}}], \"authorExternalChannelId\": \"UC9tq_bmDf9w92vDnd2oL62g\", \"contextMenuAccessibility\": {\"accessibilityData\": {\"label\": \"Chat actions\"}}, \"timestampText\": {\"simpleText\": \"-8:48\"}, \"trackingParams\": \"CAEQl98BIhMI0Mqgo6G_iAMV-JzCAR2cWziB\"}}, \"clientId\": \"CKiY0vLfr4gDFTkK1gAdHRcIAQ\"}}], \"videoOffsetTimeMsec\": \"0\"}}\n",
    "#show debug if:\n",
    "# has more than 1 action\n",
    "# has more than 1 run\n",
    "# doesn't have user\n",
    "# videoOffsetTimeMsec is lower than 0 or bigger than 7200000 (max 12 hours)\n",
    "# doesn't have message\n",
    "files = os.listdir(f\"{channel}/downloaded\")\n",
    "chat_files = [i for i in files if i.endswith(\"file_chat.json\")]\n",
    "print(chat_files)\n",
    "for file_path in chat_files:\n",
    "    all_timestamps = []\n",
    "    anomalies = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        try:\n",
    "            # Load the JSON content\n",
    "            for line in file:\n",
    "                json_data = json.loads(line.strip())\n",
    "                for item in json_data.get('replayChatItemAction', {}).get('actions', []):\n",
    "                    # Extract the timestamp\n",
    "                    if 'addChatItemAction' in item:\n",
    "                        chat_item = item['addChatItemAction']['item']\n",
    "                        if 'liveChatTextMessageRenderer' in chat_item:\n",
    "                            timestamp = chat_item['liveChatTextMessageRenderer']['timestampUsec']\n",
    "                        elif 'liveChatViewerEngagementMessageRenderer' in chat_item:\n",
    "                            timestamp = chat_item['liveChatViewerEngagementMessageRenderer']['timestampUsec']\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        # Convert to datetime object\n",
    "                        parsed_timestamp = parse_timestamp(timestamp)\n",
    "                        \n",
    "                        # Filter for timestamps that are on the 7th or 8th\n",
    "                        if parsed_timestamp.day in [7, 8]:\n",
    "                            all_timestamps.append(parsed_timestamp)\n",
    "                        else:\n",
    "                            anomalies.append(line.strip())  # Keep track of anomalous lines\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    # Create a histogram if any timestamps were collected\n",
    "    if all_timestamps:\n",
    "        create_histogram(all_timestamps, window_size_seconds)\n",
    "\n",
    "    # Display anomalous lines if any\n",
    "    if anomalies:\n",
    "        print(f\"\\nAnomalous lines detected ({len(anomalies)} lines):\")\n",
    "        for anomaly in anomalies:\n",
    "            print(anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove .tsv, .txt, .vtt files, (keeping .srt and .json), and compress json files to .json.gz in {channel}/transcripts\n",
    "transcript_files = os.listdir(f\"{channel}/transcripts\")\n",
    "for file in transcript_files:\n",
    "    if file.endswith(\".tsv\") or file.endswith(\".txt\") or file.endswith(\".vtt\"):\n",
    "        try:\n",
    "            os.remove(f\"{channel}/transcripts/{file}\")\n",
    "        except:\n",
    "            print(f\"Error removing {file}\")\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(f\"{channel}/transcripts/{file}\", \"rb\") as f:\n",
    "            with gzip.open(f\"{channel}/transcripts/{file}.gz\", \"wb\") as f_out:\n",
    "                f_out.writelines(f)\n",
    "        #remove original json file\n",
    "        try:\n",
    "            os.remove(f\"{channel}/transcripts/{file}\")\n",
    "        except:\n",
    "            print(f\"Error removing {file}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading rifLvjFgjc4\n"
     ]
    }
   ],
   "source": [
    "videos = [\"rifLvjFgjc4\"]\n",
    "for video in videos:\n",
    "    print(f\"Downloading {video}\")\n",
    "    output = os.system(f\"yt-dlp --write-subs --sub-lang live_chat --skip-download {channel_prefix}watch?v={video}\")\n",
    "    if output!=0:\n",
    "        print(f\"Error downloading {video}\")\n",
    "\n",
    "#yt-dlp --write-subs --sub-lang live_chat --write-info-json --skip-download <VIDEO_URL>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
