{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gzip\n",
    "# name of channel to be scanned\n",
    "channel_prefix = \"https://www.youtube.com/\"\n",
    "channel = \"@StronnyCuttles\"\n",
    "#channel = \"@ShibiCottonbum\"\n",
    "#channel = \"@ImmyBisou\"\n",
    "#channel = \"@IceySnowpaws\"\n",
    "#channel = \"@MercyModiste\"\n",
    "#channel = \"@AzuraDulait\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bxvGYUQqmeA\n",
      "C5M2nZUlFOI\n",
      "rAga_P8IPN8\n",
      "XzICDn_8-Jk\n",
      "BKzfzKDH4K4\n",
      "IjI_vbw789k\n",
      "h7RxzeuTUrk\n",
      "vpjDr5Uy4u4\n",
      "Ittk3Ou_R6w\n",
      "-lFoCKT-HTQ\n",
      "ARjYuEluPH8\n",
      "cNZoxeYDBrM\n",
      "N5XlaAafWhw\n",
      "g_3b5GH7dUw\n",
      "Kn5zueFswok\n",
      "WPzDPmNU4Ks\n",
      "S_Q9PvOzBrA\n",
      "kJi0-CkRM04\n",
      "Tydd2TwQKes\n",
      "TezvXw9NcmA\n",
      "LJQxOBO9R5o\n",
      "KS_or6k8Fgs\n",
      "vpE9V6Yq5mk\n",
      "lW72sUi_yGM\n",
      "jNsADJMHcH0\n",
      "-PKAkJYvLlk\n",
      "t-8BGpSdgcs\n",
      "n9V9pF55XOI\n",
      "KXrIrwwU9fE\n",
      "6y0sq0vGBz8\n",
      "tKQ7Zc0xElM\n",
      "ySbug7LOJvc\n",
      "Mh91eB_zf3I\n",
      "ato1JYpgKjg\n",
      "18xCiE-xMXI\n",
      "X3eS7c7bLBs\n",
      "ItOLT7FqIkU\n",
      "dI3Qgiy9wLY\n",
      "doQ-m-JaOWI\n",
      "Fc5YPISpWo0\n",
      "zhLGqcIL4yk\n",
      "A-5r9T4hKwA\n",
      "-qlXrLLQkzo\n",
      "eHacBfPGqGk\n",
      "B4yGQsVzcNE\n",
      "AiLh5KvhIt8\n",
      "J2I6Wss9WsQ\n",
      "5a0q3yr68IU\n",
      "FbIAzXp0TNM\n",
      "tUd0tNFVvT4\n",
      "QR3yoGDDp_E\n",
      "J7YwGiY6z2g\n",
      "2t9uBYvO2kM\n",
      "T0Jz9yri2aw\n",
      "l6e818-vgg8\n",
      "aFttYk8rGN4\n",
      "6x1Pwqmhdhk\n",
      "0pAi_PZPiT0\n",
      "zzRsF_sd1_4\n",
      "cqtBFwac9hY\n",
      "Lo0bzApA-mI\n",
      "mtPS60PrlRY\n",
      "AlJxvHKxB6s\n",
      "SkegmwvMD4I\n",
      "4IBZgfeJd7M\n",
      "5Oum6Ad7lgU\n",
      "3rIax65ailI\n",
      "Nd8iJAiB9NQ\n",
      "KjCx8ZxanXo\n",
      "VWY5nDNxgJA\n",
      "8RIWelNdr-E\n",
      "XP7BlFSaSYs\n",
      "AWji_uhsJA4\n",
      "y57y6sDhUZA\n",
      "OqUn_IWJLbU\n",
      "W6ljJwjCQj0\n",
      "J1yWMGR95r4\n",
      "1WoJxJcgWfw\n",
      "D_W1cFW-hL0\n",
      "MfQ5SKqCfhk\n",
      "GYLEhqMZ2Ro\n",
      "AiqIHq74hGk\n",
      "IB39lKeehAQ\n",
      "G0-5RfSSUP4\n",
      "pAZ6MQ5NNG8\n",
      "f7vCbTsHnT0\n",
      "Rp3BIv9szh0\n",
      "9NnBsfrL6IQ\n",
      "ha_2ykbtSUk\n",
      "NoRekuJOL_4\n",
      "t8g4TVpCsYU\n"
     ]
    }
   ],
   "source": [
    "try:   os.mkdir(channel)\n",
    "except:   pass\n",
    "try:   os.mkdir(f\"{channel}/downloaded\")\n",
    "except:   pass\n",
    "try:   os.mkdir(f\"{channel}/processed\")\n",
    "except:   pass\n",
    "try:   os.mkdir(f\"{channel}/transcripts\")\n",
    "except:   pass\n",
    "# file containing keywords\n",
    "keywords_file = \"keywords.txt\"\n",
    "\n",
    "# file containing thematic searches\n",
    "thematic_file = \"thematic.txt\"\n",
    "\n",
    "# scan channel for videos\n",
    "# live videos\n",
    "os.system(f\"yt-dlp --get-id --skip-download {channel_prefix+channel} > {channel}/videos.txt\")\n",
    "videos = []\n",
    "with open(f\"{channel}/videos.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"Error\"):\n",
    "            continue\n",
    "        videos.append(line.strip())\n",
    "\n",
    "# look for filenames in {channel}/downloaded for already downloaded videos\n",
    "# the file name contains the video id in the following format:\n",
    "# „ÄêSupermarket Simulator„ÄëDefinitely not drunk on the job üêêüçº„ÄêVAllure„Äë [i3rrDSjokF4].webm\n",
    "# where [i3rrDSjokF4] is the video id\n",
    "downloaded = []\n",
    "for file in os.listdir(f\"{channel}/downloaded\"):\n",
    "    if file.endswith(\".webm\"):\n",
    "        m = re.search(r\"\\[(.*?)\\]\", file)\n",
    "        if m:\n",
    "            downloaded.append(m.group(1))\n",
    "            \n",
    "# do the same for transcripts\n",
    "transcripts = []\n",
    "for file in os.listdir(f\"{channel}/transcripts\"):\n",
    "    if file.endswith(\".srt\"):\n",
    "        m = re.search(r\"\\[([^\\[\\]]+)\\](?!.*\\[)\", file)\n",
    "        if m:\n",
    "            transcripts.append(m.group(1))\n",
    "\n",
    "\n",
    "# compare list of videos to videos already downloaded\n",
    "to_download = list(set(videos) - set(downloaded) - set(transcripts))\n",
    "for download in to_download:\n",
    "    print(f\"{download}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading bxvGYUQqmeA\n",
      "Downloading rAga_P8IPN8\n",
      "Downloading XzICDn_8-Jk\n",
      "Downloading 8RIWelNdr-E\n",
      "Downloading XP7BlFSaSYs\n",
      "Downloading AWji_uhsJA4\n"
     ]
    }
   ],
   "source": [
    "newly_downloaded = []\n",
    "for video in to_download:\n",
    "    print(f\"Downloading {video}\")\n",
    "    output = os.system(f\"yt-dlp -f bestaudio -P {channel}/downloaded {channel_prefix}watch?v={video}\")\n",
    "    if output!=0:\n",
    "        print(f\"Error downloading {video}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect file names in {channel}/downloaded\n",
    "downloaded_files = os.listdir(f\"{channel}/downloaded\")\n",
    "for file in downloaded_files:\n",
    "    if file.endswith(\".webm\") or file.endswith(\".m4a\"):\n",
    "        #result = os.system(f\"whisper \\\"{channel}/downloaded/{file}\\\" --device cuda --output_dir --language English --model large-v3 \\\"{channel}/transcripts/\\\"\")\n",
    "        result = os.system(f\"whisper \\\"{channel}/downloaded/{file}\\\" --device cuda --language English --output_dir \\\"{channel}/transcripts/\\\"\")\n",
    "        if result==0:\n",
    "            #move file to {channel}/processed\n",
    "            try:\n",
    "                os.rename(f\"{channel}/downloaded/{file}\", f\"{channel}/processed/{file}\")\n",
    "            except:\n",
    "                print(f\"Error moving {file} to {channel}/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove .tsv, .txt, .vtt files, (keeping .srt and .json), and compress json files to .json.gz in {channel}/transcripts\n",
    "transcript_files = os.listdir(f\"{channel}/transcripts\")\n",
    "for file in transcript_files:\n",
    "    if file.endswith(\".tsv\") or file.endswith(\".txt\") or file.endswith(\".vtt\"):\n",
    "        try:\n",
    "            os.remove(f\"{channel}/transcripts/{file}\")\n",
    "        except:\n",
    "            print(f\"Error removing {file}\")\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(f\"{channel}/transcripts/{file}\", \"rb\") as f:\n",
    "            with gzip.open(f\"{channel}/transcripts/{file}.gz\", \"wb\") as f_out:\n",
    "                f_out.writelines(f)\n",
    "        #remove original json file\n",
    "        try:\n",
    "            os.remove(f\"{channel}/transcripts/{file}\")\n",
    "        except:\n",
    "            print(f\"Error removing {file}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
