{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from clarifai.client.model import Model\n",
    "\n",
    "# Your PAT (Personal Access Token) can be found in the Account's Security section\n",
    "# Specify the correct user_id/app_id pairings\n",
    "# Since you're making inferences outside your app's scope\n",
    "#USER_ID = \"clarifai\"\n",
    "#APP_ID = \"main\"\n",
    "\n",
    "# You can set the model using model URL or model ID.\n",
    "# Change these to whatever model you want to use\n",
    "# eg : MODEL_ID = \"general-english-image-caption-blip\"\n",
    "# You can also set a particular model version by specifying the  version ID\n",
    "# eg: MODEL_VERSION_ID = \"cdb690f13e62470ea6723642044f95e4\"\n",
    "#  Model class objects can be inititalised by providing its URL or also by defining respective user_id, app_id and model_id\n",
    "\n",
    "# eg : model = Model(user_id=\"clarifai\", app_id=\"main\", model_id=MODEL_ID)\n",
    "\n",
    "model_url = (\n",
    "    \"https://clarifai.com/clarifai/main/models/ethnicity-demographics-recognition\"\n",
    ")\n",
    "image_url = \"https://s3.amazonaws.com/samples.clarifai.com/featured-models/image-captioning-statue-of-liberty.jpeg\"\n",
    "\n",
    "# The Predict API also accepts data through URL, Filepath & Bytes.\n",
    "# Example for predict by filepath:\n",
    "# model_prediction = Model(model_url).predict_by_filepath(filepath, input_type=\"text\")\n",
    "\n",
    "# Example for predict by bytes:\n",
    "# model_prediction = Model(model_url).predict_by_bytes(image_bytes, input_type=\"text\")\n",
    "\n",
    "model_prediction = Model(url=model_url, pat=\"b8ffbb9120a14969a413c9eb7dc06ef5\").predict_by_url(\n",
    "    image_url, input_type=\"image\"\n",
    ")\n",
    "\n",
    "# Get the output\n",
    "print(model_prediction.outputs[0].data.concepts)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
